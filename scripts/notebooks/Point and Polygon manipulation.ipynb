{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be a tutorial in how to calculate volume, as a difference between consecutive DEMs.\n",
    "A rough overview of the steps to be followed is given below-\n",
    "1. Sort DEMs in chronological order. \n",
    "2. Inspect DEMs and Mosaics to check for distortions. \n",
    "3. Create Vector Mask to remove Areas with distortions. \n",
    "4. Mask original DEM with created vector mask. \n",
    "5. Use grass's `r.fillnulls` command to create the gaps left by the masked distortions. \n",
    "6. Obtain set of error free DEMs.\n",
    "7. Using this set, obtain delta DEMs between consecutive DEMs, or as per requirement. \n",
    "8. Do summation over obtained Delta DEM and multiply by area of a pixel, as per scale to obtain volume. \n",
    "\n",
    "\n",
    "*Note- Steps with a * \\* *indicates that there are algorithms/variables to be tuned*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> .rendered_html code { \n",
       "    padding: 2px 4px;\n",
       "    color: #c7254e;\n",
       "    background-color: #f9f2f4;\n",
       "    border-radius: 4px;\n",
       "} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Added for vector processing\n",
    "import ogr\n",
    "import os\n",
    "import json \n",
    "import osr\n",
    "import vector_processing.point_processing as pp\n",
    "#Old imports for raster processing \n",
    "import gdal\n",
    "import cv2\n",
    "from subprocess import call\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Custom Written Scripts\n",
    "try:\n",
    "    import dem_proj as dp\n",
    "    import dem_filtering as df\n",
    "    import dem_perf_check as dpc\n",
    "    from raster_chunks import GeoChunks as gc \n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Import Error. Check if dem_filtering.py is present in PYTHONPATH\")\n",
    "    print(\"PYTHONPATH = \")\n",
    "    call([\"echo\", \"$PYTHONPATH\"])\n",
    "\n",
    "# Bit of formatting to change default inline code style:\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"<style> .rendered_html code { \n",
    "    padding: 2px 4px;\n",
    "    color: #c7254e;\n",
    "    background-color: #f9f2f4;\n",
    "    border-radius: 4px;\n",
    "} </style>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Setting up PATH variables. \n",
    "\n",
    "We will continue to set up PATH variables, as and when necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_PREFIX = \"/home/madhavm/vimana/workdir/rough/vector_test/\"\n",
    "input_file = PATH_PREFIX + \"15may_trim.shp\"\n",
    "output_file = PATH_PREFIX + \"b.shp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, we we first need to convert this vector layer to a vector layer with a Projected Coordinate System, (Lat Long will be in UTM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified output file already exists.\n",
      "Deleting current file and replaing it with new points file\n",
      "Warning: Input and output layer have different projection systems\n",
      "\tThis could lead to possible errors.\n"
     ]
    }
   ],
   "source": [
    "pp.poly_as_points(polygon_file=input_file,\n",
    "                 points_file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([ 0.89166218, -0.4527014 ]),\n",
       "  array([ 0.09319471, -0.04731543]),\n",
       "  [array([  804396.21459791,  1438132.32000357]),\n",
       "   array([  804396.30779262,  1438132.27268815])]],\n",
       " [array([ 0.89167455, -0.45267704]),\n",
       "  array([ 0.408503, -0.207385]),\n",
       "  [array([  804396.30779262,  1438132.27268815]),\n",
       "   array([  804396.71629561,  1438132.06530314])]],\n",
       " [array([ 0.88532111, -0.46498014]),\n",
       "  array([ 67.91225587, -35.66824525]),\n",
       "  [array([  804396.71629561,  1438132.06530314]),\n",
       "   array([  804464.62855148,  1438096.3970579 ])]],\n",
       " [array([-0.21822709, -0.97589802]),\n",
       "  array([-10.06377107, -45.0045608 ]),\n",
       "  [array([  804464.62855148,  1438096.3970579 ]),\n",
       "   array([  804454.56478041,  1438051.3924971 ])]],\n",
       " [array([-0.97282833,  0.23152763]),\n",
       "  array([-28.55099921,   6.79497605]),\n",
       "  [array([  804454.56478041,  1438051.3924971 ]),\n",
       "   array([  804426.0137812 ,  1438058.18747315])]],\n",
       " [array([-0.38523363, -0.92281908]),\n",
       "  array([ -6.18891484, -14.82541555]),\n",
       "  [array([  804426.0137812 ,  1438058.18747315]),\n",
       "   array([  804419.82486636,  1438043.3620576 ])]],\n",
       " [array([-0.93119684,  0.36451673]),\n",
       "  array([-48.10191238,  18.82947927]),\n",
       "  [array([  804419.82486636,  1438043.3620576 ]),\n",
       "   array([  804371.72295398,  1438062.19153687])]],\n",
       " [array([-0.93119684,  0.36451673]),\n",
       "  array([-2.83843604,  1.11110494]),\n",
       "  [array([  804371.72295398,  1438062.19153687]),\n",
       "   array([  804368.88451794,  1438063.30264181])]],\n",
       " [array([ 0.36817315,  0.92975724]),\n",
       "  array([ 27.33007996,  69.01736176]),\n",
       "  [array([  804368.88451794,  1438063.30264181]),\n",
       "   array([  804396.21459791,  1438132.32000357])]],\n",
       " [array([ 0.38377704,  0.92342579]),\n",
       "  array([ 28.48148458,  68.53077266]),\n",
       "  [array([  804367.82630803,  1438063.74191549]),\n",
       "   array([  804396.30779262,  1438132.27268815])]],\n",
       " [array([ 0.3910511 ,  0.92036897]),\n",
       "  array([ 29.00866154,  68.27412489]),\n",
       "  [array([  804367.70763407,  1438063.79117825]),\n",
       "   array([  804396.71629561,  1438132.06530314])]],\n",
       " [array([ 0.94809835,  0.31797722]),\n",
       "  array([ 97.05550516,  32.55088474]),\n",
       "  [array([  804367.57304632,  1438063.84617316]),\n",
       "   array([  804464.62855148,  1438096.3970579 ])]],\n",
       " [array([ 0.82965055, -0.55828305]),\n",
       "  array([ 71.88958985, -48.37547545]),\n",
       "  [array([  804382.67519055,  1438099.76797255]),\n",
       "   array([  804454.56478041,  1438051.3924971 ])]]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that **unlike** gdal's raster bands, vector layers are 0-indexed.  \n",
    "Data -> Layers -> Geometry (For Point locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "32643\n",
      "PROJCS[\"WGS 84 / UTM zone 43N\",\n",
      "    GEOGCS[\"WGS 84\",\n",
      "        DATUM[\"WGS_1984\",\n",
      "            SPHEROID[\"WGS 84\",6378137,298.257223563,\n",
      "                AUTHORITY[\"EPSG\",\"7030\"]],\n",
      "            AUTHORITY[\"EPSG\",\"6326\"]],\n",
      "        PRIMEM[\"Greenwich\",0,\n",
      "            AUTHORITY[\"EPSG\",\"8901\"]],\n",
      "        UNIT[\"degree\",0.0174532925199433,\n",
      "            AUTHORITY[\"EPSG\",\"9122\"]],\n",
      "        AUTHORITY[\"EPSG\",\"4326\"]],\n",
      "    PROJECTION[\"Transverse_Mercator\"],\n",
      "    PARAMETER[\"latitude_of_origin\",0],\n",
      "    PARAMETER[\"central_meridian\",75],\n",
      "    PARAMETER[\"scale_factor\",0.9996],\n",
      "    PARAMETER[\"false_easting\",500000],\n",
      "    PARAMETER[\"false_northing\",0],\n",
      "    UNIT[\"metre\",1,\n",
      "        AUTHORITY[\"EPSG\",\"9001\"]],\n",
      "    AXIS[\"Easting\",EAST],\n",
      "    AXIS[\"Northing\",NORTH],\n",
      "    AUTHORITY[\"EPSG\",\"32643\"]]\n"
     ]
    }
   ],
   "source": [
    "driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "data_src = driver.Open(PATH_PREFIX + \"15may_trimUTM.shp\")\n",
    "layer = data_src.GetLayerByIndex(0)\n",
    "print(layer.GetFeatureCount())\n",
    "print(data_src.GetLayerCount())\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromEPSG(int(layer.GetSpatialRef().GetAttrValue(\"AUTHORITY\",1)))\n",
    "print(int(layer.GetSpatialRef().GetAttrValue(\"AUTHORITY\",1)))\n",
    "out_srs = osr.SpatialReference()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6facb1c5bf7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetGeometryRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExportToJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetGeometryRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetGeometryCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mp_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coordinates'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(dj['coordinates'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "f = layer[0]\n",
    "dj = json.loads(f.GetGeometryRef().ExportToJson())\n",
    "print(f.GetGeometryRef().GetGeometryCount())\n",
    "p_arr = np.array(dj['coordinates'][9])\n",
    "#print(dj['coordinates'])\n",
    "print(p_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to test out creating a vector file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_lines(point_arr):\n",
    "    lines = []\n",
    "    for i in range(point_arr.shape[0]-1):\n",
    "        temp = []\n",
    "        start_point = point_arr[i]\n",
    "        end_point = point_arr[(i+1)%point_arr.shape[0]]\n",
    "        line_vec = end_point - start_point\n",
    "        unit_vec = line_vec / np.linalg.norm(line_vec)\n",
    "        temp.append(unit_vec)\n",
    "        temp.append(line_vec)\n",
    "        temp.append([start_point,end_point])\n",
    "        lines.append(temp)\n",
    "        \n",
    "    return lines\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write function to take np.array of points along polygon as arguments, and return a list of lists. The lists inside the main list, should each define a line segment that defines the polygon. \n",
    "Format for the lists should be \n",
    "[ [unit_vec],[line_vec], [[start_point], [end_point]] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = define_lines(p_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([-0.37369812, -0.92755039]),\n",
       "  array([-1.85918336, -4.61465059]),\n",
       "  [array([  804370.30662983,  1438068.75043064]),\n",
       "   array([  804368.44744648,  1438064.13578006])]],\n",
       " [array([ 0.55638455, -0.83092493]),\n",
       "  array([ 0.33773713, -0.50438892]),\n",
       "  [array([  804368.44744648,  1438064.13578006]),\n",
       "   array([  804368.78518361,  1438063.63139114])]],\n",
       " [array([ 0.91038858, -0.41375432]),\n",
       "  array([ 2.91076583, -1.3228878 ]),\n",
       "  [array([  804368.78518361,  1438063.63139114]),\n",
       "   array([  804371.69594944,  1438062.30850333])]],\n",
       " [array([ 0.99758183,  0.06950176]),\n",
       "  array([ 0.45121001,  0.03143591]),\n",
       "  [array([  804371.69594944,  1438062.30850333]),\n",
       "   array([  804372.14715945,  1438062.33993924])]],\n",
       " [array([ 0.79365038,  0.60837413]),\n",
       "  array([ 0.25219469,  0.1933203 ]),\n",
       "  [array([  804372.14715945,  1438062.33993924]),\n",
       "   array([  804372.39935414,  1438062.53325954])]],\n",
       " [array([ 0.49563916,  0.86852854]),\n",
       "  array([ 2.57145097,  4.50605749]),\n",
       "  [array([  804372.39935414,  1438062.53325954]),\n",
       "   array([  804374.97080511,  1438067.03931702])]],\n",
       " [array([-0.93881671,  0.34441717]),\n",
       "  array([-4.66417528,  1.71111362]),\n",
       "  [array([  804374.97080511,  1438067.03931702]),\n",
       "   array([  804370.30662983,  1438068.75043064])]]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.DeleteDataSource(output_file)\n",
    "data_src = driver.CreateDataSource(output_file)\n",
    "samp_dist = 0.1\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromEPSG(32643)\n",
    "l2 = data_src.CreateLayer(\"hi\",srs,ogr.wkbPoint)\n",
    "field_id = ogr.FieldDefn(\"id\",ogr.OFTInteger)\n",
    "l2.CreateField(field_id)\n",
    "for j in range(len(t1)):\n",
    "    b = t1[j][0] * samp_dist\n",
    "    start_point = t1[j][2][0]\n",
    "    a = t1[j][1]\n",
    "    num_lines = int(np.floor(np.linalg.norm(a) / np.linalg.norm(b)))\n",
    "    for i in range(num_lines):\n",
    "        feature = ogr.Feature(l2.GetLayerDefn())\n",
    "        feature.SetField(\"id\",None)\n",
    "        t = start_point + b*i\n",
    "        wkt = \"POINT(%f %f)\" % (t[0],t[1])\n",
    "        point = ogr.CreateGeometryFromWkt(wkt)\n",
    "        feature.SetGeometry(point)\n",
    "        l2.CreateFeature(feature)\n",
    "        feature = None\n",
    "data_src = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Converting the attributes of a vector file to a CSV file .. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "data_src = driver.Open(\"/home/y13/vimana/test_out.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16june', '20may', '29apr', '03june', '15may', '14feb', '09may']\n",
      "[883.35956, 883.41852, 883.84326, 883.56702, 883.74951, 883.8573, 883.69879]\n"
     ]
    }
   ],
   "source": [
    "data_src.GetLayerCount()\n",
    "layer = data_src.GetLayerByIndex(0)\n",
    "layer.GetFeatureCount()\n",
    "f = layer[0]\n",
    "\n",
    "field_names = []\n",
    "field_values = []\n",
    "for i in range(f.GetFieldCount()):\n",
    "    field_names.append(f.GetFieldDefnRef(i).GetName())\n",
    "    field_values.append(f.GetField(i))\n",
    "print(field_names)\n",
    "print(field_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_file = open('/home/y13/vimana/out.csv','w')\n",
    "w = csv.writer(csv_file)\n",
    "#Writing Header Row to CSV\n",
    "w.writerow(field_names)\n",
    "for ftr in layer:\n",
    "    r = []\n",
    "    for i in range(ftr.GetFieldCount()):\n",
    "        r.append(ftr.GetField(i))\n",
    "    w.writerow(r)\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:VIMANA]",
   "language": "python",
   "name": "conda-env-VIMANA-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
